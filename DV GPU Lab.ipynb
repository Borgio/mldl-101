{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using GPU's on IBM POWER S822LC \n",
    "![](https://github.com/dustinvanstee/random-public-files/raw/master/s822lc_nvidia.png)\n",
    "\n",
    "In this lab, you will familiarize yourself with how to compare GPU vs CPU performance using some simple matrix math.  We will cover how tensorflow gives access to GPU and CPU, and how you can specify to the system when they can be used.\n",
    "\n",
    "You don't need to know tensorflow to complete this lab, but understanding some of tensorflow basics and matrix math will help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets get started, first lets import the tensorflow library that has been provided by the IBM PowerAI library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.12 (default, Nov 19 2016, 06:48:10) \n",
      "[GCC 5.4.0 20160609]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "# Time helper\n",
    "import timeit\n",
    "def time_run(command_str) :\n",
    "    #rv=%timeit -o -n 1 command\n",
    "    rv= timeit.Timer(stmt=command_str).timeit(number=1)\n",
    "    return rv\n",
    "\n",
    "# Print Python Version\n",
    "import os\n",
    "import sys\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify GPU Usage with Small Matrix\n",
    "Now lets build a few small matrixes and multiply them together.  Here A is 2x3 matrix, an B is 3x2 matrix.  Then we multiply them together.  By default tensorflow will use the GPU on the system if available.  Lets run this code and verify that we are using the GPU\n",
    "\n",
    "Note : To find out which devices your operations and tensors are assigned to, create the session with log_device_placement configuration option set to True as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22.  28.]\n",
      " [ 49.  64.]]\n",
      "CPU times: user 28 ms, sys: 8 ms, total: 36 ms\n",
      "Wall time: 31 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Creates a graph.\n",
    "tf.reset_default_graph() \n",
    "with tf.device('/gpu:0'):\n",
    "  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "  c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "with tf.Session() as sess :\n",
    "    writer = tf.summary.FileWriter('./graphs', graph=tf.get_default_graph())\n",
    "    sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "    # Runs the op.\n",
    "    print(sess.run(c))\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we started the jupyter notebook, we also redirected all the messages to a file so that we can see if indeed we are using the GPU.  Lets read the last couple of lines in the log file (/tmp/tensorflow.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-08 13:23:22.223420: I tensorflow/core/common_runtime/simple_placer.cc:841] MatMul: (MatMul)/job:localhost/replica:0/task:0/gpu:0\n",
      "2017-10-08 13:23:22.223441: I tensorflow/core/common_runtime/simple_placer.cc:841] b: (Const)/job:localhost/replica:0/task:0/gpu:0\n",
      "2017-10-08 13:23:22.223466: I tensorflow/core/common_runtime/simple_placer.cc:841] a: (Const)/job:localhost/replica:0/task:0/gpu:0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "tail -n 3 /tmp/tensorflow.log | grep gpu\n",
    "#echo \" ############\" >>  /tmp/tensorflow.log "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify that we can use the CPU as well with same example\n",
    "\n",
    "Here we will specify explicitly that we want to use the CPU.  By convention, tensorflow allows you to specify that by using the tf.device() method.\n",
    "\n",
    "Devices are represented by the following strings\n",
    "\n",
    "* /cpu:0 : The first cpu of your machine\n",
    "* /gpu:0 : The first gpu of your machine\n",
    "* /gpu:1 : The second gpu of your machine\n",
    "* ...\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell we specify **/cpu:0** with the exact same code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22.  28.]\n",
      " [ 49.  64.]]\n",
      "CPU times: user 20 ms, sys: 12 ms, total: 32 ms\n",
      "Wall time: 29.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf.reset_default_graph() \n",
    "# Creates a graph.\n",
    "with tf.device('/cpu:0'):\n",
    "  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "  c = tf.matmul(a, b)\n",
    "\n",
    "# Creates a session with log_device_placement set to True.\n",
    "with tf.Session() as sess :\n",
    "    writer = tf.summary.FileWriter('./graphs', graph=tf.get_default_graph())\n",
    "    sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "    # Runs the op.\n",
    "    print(sess.run(c))\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets make sure that we used the cpu ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-08 13:23:42.170233: I tensorflow/core/common_runtime/simple_placer.cc:841] MatMul: (MatMul)/job:localhost/replica:0/task:0/cpu:0\n",
      "2017-10-08 13:23:42.170257: I tensorflow/core/common_runtime/simple_placer.cc:841] b: (Const)/job:localhost/replica:0/task:0/cpu:0\n",
      "2017-10-08 13:23:42.170283: I tensorflow/core/common_runtime/simple_placer.cc:841] a: (Const)/job:localhost/replica:0/task:0/cpu:0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "tail -n 3 /tmp/tensorflow.log | grep cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice here that now we are mapping all the operations to the cpu. \n",
    "\n",
    "\n",
    "Also notice we dont really get a large speedup.  Thats becuase the example is to small to make use of the parallelism advantage inherent in the GPU.  Next, we will rerun but this time will very large matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Speedup test with 20 Billion cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -5.07367477e+01   1.39379993e-01  -1.53627777e+02 ...,   5.84249687e+01\n",
      "    2.82826061e+01   1.28241638e+02]\n",
      " [  4.70148773e+01   2.84630737e+01   9.40551758e+01 ...,  -8.43005447e+01\n",
      "   -4.17779198e+01  -7.09997330e+01]\n",
      " [  7.76378632e+01   8.77513790e+00   1.40971050e+01 ...,   2.48998404e+00\n",
      "    1.97348862e+02   2.57942322e+02]\n",
      " ..., \n",
      " [  9.67471390e+01  -1.07339268e+01   1.13605019e+02 ...,  -4.05519371e+01\n",
      "    3.17055073e+01  -8.93909531e+01]\n",
      " [ -4.58382835e+01   4.80116558e+00  -1.30733433e+01 ...,   3.78868942e+01\n",
      "   -3.17662792e+01  -5.00178635e-01]\n",
      " [  7.40732651e+01   1.87222099e+01   5.84146767e+01 ...,   1.65686737e+02\n",
      "   -6.16308594e+01  -4.19055481e+01]]\n",
      "CPU times: user 836 ms, sys: 380 ms, total: 1.22 s\n",
      "Wall time: 1.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf.reset_default_graph() \n",
    "\n",
    "mat1 = tf.random_normal([20000,10000],mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "mat2 = tf.random_normal([10000,10000],mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "mat3 = tf.matmul(mat1, mat2)\n",
    "\n",
    "# Creates a session with log_device_placement set to True.\n",
    "with tf.Session() as sess :\n",
    "    writer = tf.summary.FileWriter('./graphs', graph=tf.get_default_graph())\n",
    "    sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "    # Runs the op.\n",
    "    print(sess.run(mat3))\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Notice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-139.45901489  -88.81645203  -43.53620148 ...,   52.38720703\n",
      "    75.01547241   50.5382843 ]\n",
      " [  45.14087296   -1.33799887 -191.29249573 ...,   61.72611237\n",
      "     2.22061539  -27.41448212]\n",
      " [-121.50714111 -121.08638763  -77.48414612 ...,   40.93670273\n",
      "    76.60482025   36.93449402]\n",
      " ..., \n",
      " [  64.00627899  105.14516449  122.32860565 ..., -151.68490601\n",
      "   -96.64914703 -186.93591309]\n",
      " [ -12.83614635  -57.50984955  170.74624634 ...,  -59.76148987\n",
      "   -66.51875305   41.46344376]\n",
      " [-172.24754333    4.39118052  -36.03226852 ..., -148.16416931\n",
      "    40.98770905  -10.31962013]]\n",
      "CPU times: user 17min 34s, sys: 1.04 s, total: 17min 35s\n",
      "Wall time: 33.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf.reset_default_graph() \n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    mat1 = tf.random_normal([20000,10000],mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "    mat2 = tf.random_normal([10000,10000],mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "    mat3 = tf.matmul(mat1, mat2)\n",
    "\n",
    "    # Creates a session with log_device_placement set to True.\n",
    "with tf.Session() as sess :\n",
    "    writer = tf.summary.FileWriter('./graphs', graph=tf.get_default_graph())\n",
    "    sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "    # Runs the op.\n",
    "    print(sess.run(mat3))\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "If you were to check vmstat on your termnical, you would notice that all 32 CPU cores are working to multiply this matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 954 ns per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -o -n 1 a=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Runtime = \" + str(a) + \" sec\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU SPEEDUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildRuns(mata_size,matb_size) :\n",
    "    mata_size = str(mata_size)\n",
    "    matb_size = str(matb_size)\n",
    "\n",
    "    GPURUN = \"\"\"\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph() \n",
    "\n",
    "mat1 = tf.random_normal([\"\"\" + mata_size + ',' +matb_size + \"\"\"],mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "mat2 = tf.random_normal([\"\"\" + mata_size + ',' +matb_size + \"\"\"],mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "mat3 = tf.matmul(mat1, mat2)\n",
    "\n",
    "# Creates a session with log_device_placement set to True.\n",
    "with tf.Session() as sess :\n",
    "    writer = tf.summary.FileWriter('./graphs', graph=tf.get_default_graph())\n",
    "    sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "    # Runs the op.\n",
    "    sess.run(mat3)\n",
    "    sess.close()\n",
    "    \"\"\"\n",
    "    \n",
    "    CPURUN = \"\"\"\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph() \n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    mat1 = tf.random_normal([\"\"\" + mata_size + ',' +matb_size + \"\"\"],mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "    mat2 = tf.random_normal([\"\"\" + mata_size + ',' +matb_size + \"\"\"],mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "    mat3 = tf.matmul(mat1, mat2)\n",
    "\n",
    "    # Creates a session with log_device_placement set to True.\n",
    "with tf.Session() as sess :\n",
    "    writer = tf.summary.FileWriter('./graphs', graph=tf.get_default_graph())\n",
    "    sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "    # Runs the op.\n",
    "    sess.run(mat3)\n",
    "    sess.close()\n",
    "    \"\"\"\n",
    "    return (GPURUN,CPURUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'improt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-79dec3e6b0a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'(GPURUN,CPURUN) = buildRuns(10,10)\\nimprot\\n#print CPURUN\\nruns = [10,100]\\ngpu_time=time_run(GPURUN)\\ncpu_time=time_run(CPURUN)\\nspeedup = cpu_time / gpu_time\\nprint \"Speedup for a matrix multiply of 20B Cells = \" + str(speedup)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2101\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2103\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2104\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'improt' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "(GPURUN,CPURUN) = buildRuns(10,10)\n",
    "improt\n",
    "#print CPURUN\n",
    "runs = [10,100]\n",
    "gpu_time=time_run(GPURUN)\n",
    "cpu_time=time_run(CPURUN)\n",
    "speedup = cpu_time / gpu_time\n",
    "print \"Speedup for a matrix multiply of 20B Cells = \" + str(speedup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more reading about GPUs ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "useful stackoverflows\n",
    "https://stackoverflow.com/questions/46178961/duplicate-tensorflow-placeholder-variables\n",
    "https://stackoverflow.com/questions/37660312/run-tensorflow-on-cpu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
